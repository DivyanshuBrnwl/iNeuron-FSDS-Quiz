{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e7502b",
   "metadata": {},
   "source": [
    "1. What is the main difference between linear and logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad75215",
   "metadata": {},
   "source": [
    "Ans. The main difference between linear and logistic regression is that linear regression is used to predict continuous values, while logistic regression is used to predict binary outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a0552",
   "metadata": {},
   "source": [
    "2. In linear regression, what is the purpose of the cost function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3bdcf",
   "metadata": {},
   "source": [
    "The cost function in linear regression is used to measure the difference between the predicted values and the actual values. It helps in finding the best-fitting line by minimizing the cost function.Ans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f96b425",
   "metadata": {},
   "source": [
    "3. What is the advantage of using support vector machines (SVM) for classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778269f4",
   "metadata": {},
   "source": [
    "Ans. One advantage of using support vector machines for classification is their effectiveness in high-dimensional spaces, even where the number of dimensions is greater than the number of samples. They are also versatile as different Kernel functions can be specified for the decision function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c801042",
   "metadata": {},
   "source": [
    "4. What does the 'support vector' refer to in Support Vector Machines (SVM)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8bb44",
   "metadata": {},
   "source": [
    "Ans. Support vectors are the data points that are the closest to the decision boundary (hyperplane) and ultimately determine the position and orientation of the hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac39cd",
   "metadata": {},
   "source": [
    "5. What is the purpose of the kernel trick in SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc9ebfa",
   "metadata": {},
   "source": [
    "Ans. The kernel trick allows SVM to operate in a higher-dimensional space without explicitly calculating the new coordinates of the data, which can lead to efficient classification of non-linear data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7056217",
   "metadata": {},
   "source": [
    "6. What is the objective of Support Vector Regression (SVR)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c308c4",
   "metadata": {},
   "source": [
    "Ans. The objective of SVR is to find the best-fitting line within a specified margin that captures a specific percentage of the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a45ac",
   "metadata": {},
   "source": [
    "7. What does the entropy measure in decision trees represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b121362",
   "metadata": {},
   "source": [
    "Ans. Entropy in decision trees represents the impurity or randomness in a dataset. A lower entropy value indicates higher homogeneity, while a higher entropy value indicates higher diversity or impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eccbbfe",
   "metadata": {},
   "source": [
    "8. What is pruning in the context of decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73cb09",
   "metadata": {},
   "source": [
    "Ans. Pruning in decision trees is the process of reducing the size of the tree by removing non-essential nodes to improve its generalization ability and prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4859b58",
   "metadata": {},
   "source": [
    "9. Which of the following is a drawback of decision tree algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26521f",
   "metadata": {},
   "source": [
    "Ans. One drawback of decision tree algorithms is their susceptibility to overfitting, especially when dealing with complex datasets with many features and deep trees. They can also be sensitive to small variations in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166356ae",
   "metadata": {},
   "source": [
    "10. In logistic regression, the Sigmoid function is used to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbec76b",
   "metadata": {},
   "source": [
    "Ans. The Sigmoid function in logistic regression is used to map predicted values to probabilities, which ensures that the output is between 0 and 1, representing the probability of the input belonging to a certain class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
